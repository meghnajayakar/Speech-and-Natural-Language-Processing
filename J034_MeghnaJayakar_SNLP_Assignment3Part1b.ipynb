{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8L28Kn_m3gC",
        "outputId": "8d2e6c78-b3b6-485a-db4e-6a2a3c502998"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "from wordcloud import WordCloud\n",
        "import re\n",
        "import gensim.downloader as api\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"IMDB Dataset.csv\")"
      ],
      "metadata": {
        "id": "msDIZx0xor7W"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "remove_html = re.compile(r'<.*?>')\n",
        "non_alpha_pattern = re.compile(r'[^a-z\\s]')\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = remove_html.sub(' ', text)\n",
        "    text = non_alpha_pattern.sub('', text)\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    return ' '.join(tokens)"
      ],
      "metadata": {
        "id": "meTjEAUjo-e8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_data_in_chunks(df, chunk_size = 5000):\n",
        "    cleaned_chunks = []\n",
        "    for start in range(0, df.shape[0], chunk_size):\n",
        "        end = start + chunk_size\n",
        "        chunk = df.iloc[start:end].copy()\n",
        "        chunk['cleaned_review'] = chunk['review'].apply(clean_text)\n",
        "        cleaned_chunks.append(chunk)\n",
        "    return pd.concat(cleaned_chunks, ignore_index = True)"
      ],
      "metadata": {
        "id": "5mucMCOdpL3p"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned = process_data_in_chunks(df)"
      ],
      "metadata": {
        "id": "D0nCCZ38pNS9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned['tokens'] = df_cleaned['cleaned_review'].apply(word_tokenize)"
      ],
      "metadata": {
        "id": "2sfsQ3zbpPIV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, val_data = train_test_split(df_cleaned, test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "UFvDJh2TpQi1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "4kIIbxzXpSKH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab_and_mapping(tokenized_texts):\n",
        "    vocab = set(word for tokens in tokenized_texts for word in tokens)\n",
        "    word_to_index = {word: idx + 2 for idx, word in enumerate(vocab)}  # Start indexing from 2\n",
        "    word_to_index['<PAD>'] = 0  # Padding token\n",
        "    word_to_index['<UNK>'] = 1  # Unknown token\n",
        "    return word_to_index"
      ],
      "metadata": {
        "id": "m5xsk2fMpj8Z"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_tokens(tokens, word_to_index):\n",
        "    return [word_to_index.get(token, word_to_index['<UNK>']) for token in tokens]"
      ],
      "metadata": {
        "id": "nD2m4DcjpnRt"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index = build_vocab_and_mapping(train_data['tokens'])\n",
        "train_data['encoded'] = train_data['tokens'].apply(lambda tokens: encode_tokens(tokens, word_to_index))\n",
        "val_data['encoded'] = val_data['tokens'].apply(lambda tokens: encode_tokens(tokens, word_to_index))"
      ],
      "metadata": {
        "id": "S-QaLuBMppWT"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.texts = texts\n",
        "        self.labels = torch.tensor(labels.values, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.texts.iloc[idx], dtype=torch.long), self.labels[idx]"
      ],
      "metadata": {
        "id": "FFqtXw8cprbc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    texts, labels = zip(*batch)\n",
        "    texts_padded = pad_sequence(texts, batch_first=True, padding_value=0)\n",
        "    return texts_padded, torch.stack(labels)"
      ],
      "metadata": {
        "id": "_eiUkWsDpu8n"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = {'positive': 1, 'negative': 0}\n",
        "train_data['target'] = train_data['sentiment'].map(labels)\n",
        "val_data['target'] = val_data['sentiment'].map(labels)"
      ],
      "metadata": {
        "id": "FX-hWyGMp4oP"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "train_dataset = TextDataset(train_data['encoded'], train_data['target'])\n",
        "val_dataset = TextDataset(val_data['encoded'], val_data['target'])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "M4COKPl6pxAh"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "fqaY53LsqDu7",
        "outputId": "6e47e9df-ddb3-4749-a512-da1e30b34ab8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim=100, hidden_dim=128, output_dim=1):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, hidden = self.rnn(embedded)\n",
        "        return self.sigmoid(self.fc(hidden.squeeze(0)))"
      ],
      "metadata": {
        "id": "er8B1YDWp0zP"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim=100, hidden_dim=128, output_dim=1):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, (hidden, _) = self.lstm(embedded)\n",
        "        return self.sigmoid(self.fc(hidden[-1]))"
      ],
      "metadata": {
        "id": "tzXy0hRvp_Ww"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(word_to_index)\n",
        "rnn_model = RNNModel(vocab_size).to(device)\n",
        "lstm_model = LSTMModel(vocab_size).to(device)"
      ],
      "metadata": {
        "id": "xairyqddqGYC"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(rnn_model.parameters()).device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUensqmCqJpt",
        "outputId": "f57a1297-cf98-49c2-b889-70bf6cbe4aa7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=3, device=device):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for texts, labels in train_loader:\n",
        "            texts = texts.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(texts).squeeze()\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Validation phase\n",
        "        val_loss = 0\n",
        "        # model.eval()\n",
        "        with torch.inference_mode():\n",
        "            for texts, labels in val_loader:\n",
        "                texts = texts.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = model(texts).squeeze()\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch {epoch+1}, Training Loss: {total_loss / len(train_loader)}, Validation Loss: {val_loss / len(val_loader)}')\n",
        "    return model"
      ],
      "metadata": {
        "id": "QDABxdusqQpM"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "rnn_optimizer = torch.optim.Adam(rnn_model.parameters(), lr=1e-3)\n",
        "lstm_optimizer = torch.optim.Adam(lstm_model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "ULpxBZm7qqCA"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train RNN model\n",
        "print(\"Training RNN Model\")\n",
        "rnn_model = train_model(rnn_model, train_loader, val_loader, criterion, rnn_optimizer, num_epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPYulT2sqtLz",
        "outputId": "251d87f8-9e35-4c07-d7da-d78c4ac0f85d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training RNN Model\n",
            "Epoch 1, Training Loss: 0.6957648281097412, Validation Loss: 0.6943879144641157\n",
            "Epoch 2, Training Loss: 0.6953449727058411, Validation Loss: 0.6936638071514166\n",
            "Epoch 3, Training Loss: 0.6935484541893006, Validation Loss: 0.6933731950890903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train LSTM model\n",
        "print(\"\\nTraining LSTM Model\")\n",
        "lstm_model = train_model(lstm_model, train_loader, val_loader, criterion, lstm_optimizer, num_epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBLvwj_FqtIS",
        "outputId": "96bc460a-c779-4e4d-8464-ca4e740f5d50"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training LSTM Model\n",
            "Epoch 1, Training Loss: 0.693178857088089, Validation Loss: 0.6927582183584999\n",
            "Epoch 2, Training Loss: 0.6913622262001038, Validation Loss: 0.6928665883624896\n",
            "Epoch 3, Training Loss: 0.6883591244220734, Validation Loss: 0.6911223050885307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, val_loader):\n",
        "    model.to('cpu')\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for texts, labels in val_loader:\n",
        "            outputs = model(texts).squeeze()\n",
        "            preds = (outputs > 0.5).float()\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_targets.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = np.mean(np.array(all_preds) == np.array(all_targets))\n",
        "    print(f'Validation Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "2_BQ5gGBrb3N"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate RNN model\n",
        "print(\"Evaluating RNN Model\")\n",
        "evaluate_model(rnn_model, val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTX9SCrcrqX6",
        "outputId": "5e254f32-817a-40c8-e6fd-6dc2013dbd53"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating RNN Model\n",
            "Validation Accuracy: 0.5089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate LSTM model\n",
        "print(\"\\nEvaluating LSTM Model\")\n",
        "evaluate_model(lstm_model, val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOlvUw-wrtID",
        "outputId": "7012ef45-4224-47df-a559-87e1ec8834e0"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating LSTM Model\n",
            "Validation Accuracy: 0.5026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wsQK8__Mrvc5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}